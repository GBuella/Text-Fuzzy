=encoding UTF-8

=head1 NAME

Text::Fuzzy - partial or fuzzy string matching using edit distances

=head1 SYNOPSIS

    use Text::Fuzzy;
    my $tf = Text::Fuzzy->new ('boboon');
    print "Distance is ", $tf->distance ('babboon'), "\n";
    # Prints "Distance is 2"
    my @words = qw/the quick brown fox jumped over the lazy dog/;
    my $nearest = $tf->nearest (\@words);
    print "Nearest array entry is ", $words[$nearest], "\n";
    # Prints "Nearest array entry is brown"

=head1 DESCRIPTION

This module calculates the Levenshtein edit distance between words,
and does edit-distance-based searching of arrays and files to find the
nearest entry. It can handle either byte strings or character strings
(strings containing Unicode), treating each Unicode character as a
single entity.

It is designed for high performance in searching for the nearest to a
particular search term over an array of words or a file, by reducing
the number of calculations which needs to be performed.

It supports either bytewise edit distances or Unicode-based edit distances:

    use utf8;
    my $tf = Text::Fuzzy->new ('あいうえお☺');
    print $tf->distance ('うえお☺'), "\n";
    # prints "2".

The default edit distance is the Levenshtein edit distance, which
applies an equal weight of one to additions (C<cat> -> C<cart>),
substitutions (C<cat> -> C<cut>), and deletions (C<carp> ->
C<cap>). Optionally, the Damerau-Levenshtein edit distance, which
additionally allows transpositions (C<salt> -> C<slat>) may be
selected using the method L</transpositions_ok>.

=head1 METHODS

=head2 new

    my $tf = Text::Fuzzy->new ('bibbety bobbety boo');

Create a new Text::Fuzzy object from the supplied word.

=head2 distance

    my $dist = $tf->distance ($word);

Return the edit distance to C<$word> from the word used to create the
object in L</new>.

=head2 nearest

    my $index = $tf->nearest (\@words);

This returns the index of the nearest element in the array to the
argument to L</new>. If none of the elements are less than the maximum
distance away from the word, C<$index> is -1.

    if ($index >= 0) {
        printf "Found at $index, distance was %d.\n",
            $tf->last_distance ();
    }

Use L</set_max_distance> to alter the maximum distance used.

=head2 last_distance

    my $last_distance = $tf->last_distance ();

The distance from the previous match closest match. This is used in
conjunction with L</nearest> to find the edit distance to the previous
match.

=head2 set_max_distance

    # Set the max distance.
    $tf->set_max_distance (3);

Set the maximum edit distance of C<$tf>. The default maximum distance
is 10. Set the maximum distance to a low value to improve the speed
of searches over lists with L</nearest>, or to reject unlikely
matches. When searching for a near match, anything with an edit
distance of a value at least as high as the maximum is rejected
without computing the exact distance. To compute exact distances, call
this method with zero or undefined, the maximum edit distance is
switched off, and whatever the nearest match is is accepted.

=head2 get_max_distance

    # Get the maximum edit distance.
    print "The max distance is ", $tf->get_max_distance (), "\n";

Get the maximum edit distance of C<$tf>. The default is set to 10. The
maximum distance may be set with L</set_max_distance>.

=head2 scan_file

    $tf->scan_file ('/usr/share/dict/words');

Scan a file to find the nearest match to the word used in
L</new>. This assumes that the file contains lines of text separated
by newlines and finds the closest match in the file.

This does not currently support Unicode-encoded files.

=head2 transpositions_ok

    $tf->transpositions_ok (1);

This changes the type of edit distance used to allow or disallow
transpositions, such as C<clam> and C<calm>. Initially transpositions
are not allowed, giving the Levenshtein edit distance. If
transpositions are used, the edit distance becomes the
Damerau-Levenshtein edit distance.

=head1 PRIVATE METHODS

These methods are not expected to be useful for the general user. They
may be useful in benchmarking the module and checking its correctness.

=head2 no_alphabet

    $tf->no_alphabet (1);

This turns off alphabetizing of the string. Alphabetizing is a filter
where the intersection of all the characters in the two strings is
computed. If the number of characters in the difference of the two
strings is greater than the maximum distance, the match is rejected
without applying the dynamic programming algorithm. This results in a
speed increase due to the computational cost of the dynamic
programming algorithm. The alphabetizing should not ever reject
anything which is a legitimate match, and it should make the program
run faster in almost every case. Thus this method is private, since
the only envisaged uses of switching this check off are checking that
the algorithm is working correctly, and benchmarking performance.

=head2 get_trans

This returns the value set by L</transpositions_ok>.

=head2 unicode_length

This returns the length in characters (not bytes) of the string used
in L</new>. If the string is not marked as Unicode, it returns the
undefined value.

=head2 ualphabet_rejected

    my $rejected = $tf->ualphabet_rejected ();

After running L</nearest> over an array, this returns the number of
entries of the array which were rejected using only the alphabet. Its
value is reset to zero each time L</nearest> is called.

=head1 EXAMPLES

=head2 misspelt-web-page.cgi

The file F<examples/misspelt-web-page.cgi> is an example of a CGI
script which does something similar to the Apache mod_speling module,
offering spelling corrections for mistyped URLs and sending the user
to a correct page.

See the file in the distribution for details. See also
L<http://www.lemoda.net/perl/perl-mod-speling/> for how to set up
F<.htaccess> to use the script.

=head2 spell-check.pl

The file F<examples/spell-check.pl> is a spell checker. It uses a
dictionary of words specified by a command-line option "-d":

    spell-check.pl -d /usr/dict/words file1.txt file2.txt

It prints out any words which look like spelling mistakes, using the
dictionary.

Because the usual Unix dictionary doesn't have plurals, it uses
L<Lingua::EN::PluralToSingular>, to convert nouns into singular
forms. Unfortunately it still misses past participles and past tenses
of verbs.

=head2 extract-kana.pl

The file F<examples/extract-kana.pl> extracts the kana entries from
"edict", a freely-available Japanese to English electronic dictionary,
and does some fuzzy searches on them. It requires a local copy of the
file to run. This script demonstrates the use of Unicode searches with
Text::Fuzzy.

=head1 ACKNOWLEDGEMENTS

The edit distance including transpositions was contributed by Nick
Logan (UGEXE). Some of the tests in F<t/trans.t> are taken from the
L<Text::Levenshtein::Damerau::XS> module.

[% INCLUDE "author" %]
